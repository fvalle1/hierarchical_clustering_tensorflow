{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(data, name=\"distances\"):\n",
    "    return tf.map_fn(lambda A: tf.map_fn(lambda B: tf.norm(A-B), data), data, name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linkage(first, second, name=\"linkage\"):\n",
    "    return tf.reduce_mean([first, second], axis=0, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_row(data, row=tf.constant(0, dtype=tf.int64), name=\"drop_row\"):\n",
    "    return tf.concat([tf.slice(data,[tf.constant(0, dtype=tf.int64),0],[row,-1]),tf.slice(data,[row+tf.constant(1, dtype=tf.int64),0],[-1,-1])], axis=0, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_list = [[1,2,10],[1,2,4],[1,2,3],[1,3,6],[3,4,8],[1,3,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "data = tf.constant(data_list, dtype=tf.float64, name=\"data\")\n",
    "new_data = tf.Variable(data, name = \"data_variable\")##variable should change shape\n",
    "npoints = data.shape[0].value\n",
    "steps = npoints\n",
    "n_max_clusters = npoints ##max number\n",
    "n_actual_clusters = npoints ##currently considered\n",
    "assignments = np.linspace(0.,npoints-1,npoints)\n",
    "sizes = np.ones_like(assignments)\n",
    "orig_shape = data.shape[0]\n",
    "Z = []\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"graph/\", sess.graph)\n",
    "    sess.run(init)\n",
    "    start=time.time()\n",
    "    for i in range(steps-1):\n",
    "        print(\"step\",i)\n",
    "        distances = distance(new_data)\n",
    "        n = distances.shape[0]\n",
    "        #remove diagonal\n",
    "        nddistances = tf.reshape(tf.boolean_mask(distances,tf.logical_not(tf.equal(distances,tf.zeros_like(distances)))),(n,n-1))#1 is diagonal\n",
    "        actual_minimums = tf.sort(tf.sort(tf.where(tf.equal(tf.reduce_min(nddistances),distances)), axis=1), axis=0, name=\"assignemts\")[0]\n",
    "        original_cluster_indexes = tf.gather(assignments, tf.cast(actual_minimums, tf.int64), name=\"correct_assignemts\")\n",
    "        if verbose:\n",
    "            print(\"merging..\",original_cluster_indexes.eval())\n",
    "        min_distance = tf.cast(distances[actual_minimums[0]][actual_minimums[1]], tf.float64, name=\"minimum_distance\")\n",
    "        #mean position of new cluster\n",
    "        new_pos = get_linkage(new_data[actual_minimums[0]],new_data[actual_minimums[1]], name=\"linkage\")\n",
    "        assignments=np.delete(assignments,actual_minimums.eval())\n",
    "        n_actual_clusters-=2\n",
    "        #add new cluster to data\n",
    "        data=tf.concat([data,[new_pos]], axis=0)\n",
    "        #update assignments of merged clusters\n",
    "        assignments = np.concatenate([assignments, [n_max_clusters]], axis=0)##new cluster\n",
    "        #extimate size of the new cluster and append to others\n",
    "        current_size=np.sum(sizes[np.array(original_cluster_indexes.eval()).astype(int)])\n",
    "        sizes = np.concatenate([sizes, [current_size]])\n",
    "        n_actual_clusters+=1\n",
    "        if verbose:\n",
    "            print(\"current clusters..\",assignments)\n",
    "            print(\"current sizes..\", sizes)\n",
    "        new_data = tf.Variable(tf.zeros((n_actual_clusters,data.shape[1]), dtype=tf.float64), dtype=tf.float64)\n",
    "        tf.assign(new_data,tf.gather(data, tf.cast(assignments,tf.int64)), validate_shape=False).eval()\n",
    "        #new_data = tf.reshape(new_data, (n_actual_clusters,data.shape[1]))\n",
    "        if verbose:\n",
    "            print(\"data..\",new_data.eval(),\" with shape..\", new_data.shape)\n",
    "        n_max_clusters = n_max_clusters+1\n",
    "        Z.append(tf.stack([original_cluster_indexes[0], original_cluster_indexes[1], min_distance, current_size],0).eval())\n",
    "    Z=np.array(Z).astype(float)\n",
    "    print(\"Z..\",Z)\n",
    "print(\"runed in..\",time.time()-start,\" seconds\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zpy = linkage(data_list)\n",
    "Zpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.subplots(1,2)\n",
    "ax[0].set_title(\"tensorflow\")\n",
    "dendrogram(Z,ax=ax[0])\n",
    "ax[1].set_title(\"scipy\")\n",
    "dendrogram(Zpy, ax = ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering()\n",
    "model.fit_predict(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcluster(Z, t=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
